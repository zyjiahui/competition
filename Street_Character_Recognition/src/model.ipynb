{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataprocess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_loader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n",
      "File \u001b[0;32m~/Deep_Learning/tianchi/Street_Character_Recognition/src/dataprocess.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m train_path \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/mchar_train/*.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# mchar_train文件中的所有图片\u001b[39;00m\n\u001b[1;32m     39\u001b[0m train_path\u001b[38;5;241m.\u001b[39msort()  \u001b[38;5;66;03m# 按字母顺序排列\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m train_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/train.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# 载入json文件  路径容易写错\u001b[39;00m\n\u001b[1;32m     41\u001b[0m train_label \u001b[38;5;241m=\u001b[39m [train_json[x][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m train_json]  \u001b[38;5;66;03m# 在标签的json文件中，将标签label的内容提取出来，存储为列表list[]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 加入DataLoader的数据读取函数  DataLoader：对Dataset进行封装，提供批量读取的迭代读取\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/train.json'"
     ]
    }
   ],
   "source": [
    "from dataprocess import train_loader\n",
    "import torch\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1,self).__init__()\n",
    "        # CNN特征提取模块\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=(3,3),stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,kernel_size=(3,3),stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # 6个全连接层分类\n",
    "        self.fc1 = nn.Linear(32*3*7,11)\n",
    "        self.fc2 = nn.Linear(32*3*7,11)\n",
    "        self.fc3 = nn.Linear(32*3*7,11)\n",
    "        self.fc4 = nn.Linear(32*3*7,11)\n",
    "        self.fc5 = nn.Linear(32*3*7,11)\n",
    "        self.fc6 = nn.Linear(32*3*7,11)\n",
    "\n",
    "    def forward(self,x):  \n",
    "        feat = self.cnn(x)\n",
    "        # 全连接之前需要将之前的数据拉平\n",
    "        feat = feat.view(feat.shape[0],-1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1,c2,c3,c4,c5,c6\n",
    "\n",
    "model = SVHN_Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_loader\u001b[49m:\n\u001b[1;32m     14\u001b[0m         c0,c1,c2,c3,c4,c5 \u001b[38;5;241m=\u001b[39m model(data[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# 第一个图的6个位置的模型输出概率[p1，p2，p3，p4，p5，p6]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# 计算每一个字符的损失，并相加得处总损失，再求平均\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# criterion参数（模型输出结果，真实标签），以此求出损失\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# 学习率\n",
    "lr = 0.005\n",
    "epochs = 10\n",
    "# 定义损失\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 定义优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "loss_plot = []  # 记录损失\n",
    "c0_plot = []  # 记录正确率\n",
    "# 训练\n",
    "for epoch in range(epochs):\n",
    "    for data in train_loader:\n",
    "        c0,c1,c2,c3,c4,c5 = model(data[0])  # 第一个图的6个位置的模型输出概率[p1，p2，p3，p4，p5，p6]\n",
    "        # 计算每一个字符的损失，并相加得处总损失，再求平均\n",
    "        # criterion参数（模型输出结果，真实标签），以此求出损失\n",
    "        loss = criterion(c0, data[1][:, 0]) + \\\n",
    "                criterion(c1, data[1][:, 1]) + \\\n",
    "                criterion(c2, data[1][:, 2]) + \\\n",
    "                criterion(c3, data[1][:, 3]) + \\\n",
    "                criterion(c4, data[1][:, 4]) + \\\n",
    "                criterion(c5, data[1][:, 5])\n",
    "        loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_plot.append(loss.item())\n",
    "        c0_plot.append((c0.argmax(1) == data[1][:,0]).sum().item()*1.0 / c0.shape[0])\n",
    "    print(epoch)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
